{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workbook to compute cross correlation data on the extracted time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%config InlineBackend.figure_format = 'svg' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import group_data as gd\n",
    "import flylib\n",
    "import pylab as plb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "swarm_data = dict()\n",
    "for key in gd.swarms.keys():\n",
    "    paths = dict()\n",
    "    for fly in gd.swarms[key].flies:\n",
    "        if not(os.path.exists(fly.fly_path + 'nnls_fits_no_bk_dF_F_corr_data.cpkl')):\n",
    "            paths[fly.fly_num] =  {'fly_path':fly.fly_path,'fly_num':fly.fly_num}\n",
    "    swarm_data[key] = paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_signal_dict(fly_path):\n",
    "    \"\"\"extract a dictionary of signals for a given fly\n",
    "    probably want to atach to the fly class\"\"\"\n",
    "    import h5py\n",
    "    import cPickle\n",
    "    import numpy as np\n",
    "    muscle_data_file = fly_path+'nnls_fits_no_bk_dF_F.cpkl'\n",
    "    fly_record_file = fly_path+'fly_record.hdf5'\n",
    "    signal_dict = dict()\n",
    "    fi = open(muscle_data_file,'rb')\n",
    "    muscle_data = cPickle.load(fi)\n",
    "    fi.close()\n",
    "    for mu,sig in zip(muscle_data['muscles'],muscle_data['fits']):\n",
    "        signal_dict[mu] = sig\n",
    "    hf = h5py.File(fly_record_file,'r')\n",
    "    exp_record = hf['experiments'].values()[0]\n",
    "    for key in exp_record['tiff_data']['axon_framebase'].keys():\n",
    "        signal_dict[key] = np.array(exp_record['tiff_data']['axon_framebase'][key])\n",
    "    hf.close()\n",
    "    return signal_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458\n",
      "459\n",
      "460\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "453\n",
      "455\n",
      "456\n",
      "461\n",
      "462\n",
      "463\n",
      "313\n",
      "313\n",
      "[Errno 2] No such file or directory: '/media/FlyDataC/FlyDB/Fly0313/nnls_fits_no_bk_dF_F.cpkl'\n",
      "450\n",
      "452\n",
      "432\n",
      "433\n",
      "430\n",
      "431\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "442\n",
      "443\n"
     ]
    }
   ],
   "source": [
    "#trim the swarm dict to remove any flies with problems\n",
    "for swarm in swarm_data.values():\n",
    "    for flykey in swarm.keys():\n",
    "        fly = swarm[flykey]\n",
    "        try:\n",
    "            print fly['fly_num']\n",
    "            fly['sigs'] = get_signal_dict(fly['fly_path'])\n",
    "        except IOError as er:\n",
    "            print flykey\n",
    "            swarm.pop(flykey)\n",
    "            print er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_line_database(line_name):\n",
    "    \"\"\"pull out the saved database of muscle expression proflies\"\"\"\n",
    "    line_name = line_name.split('_GFP')[0].split('GMR')[1]\n",
    "    import cPickle\n",
    "    f = open('../../../mn_expression_matrix_plot/line_database.cpkl','rb')\n",
    "    line_database = cPickle.load(f)\n",
    "    f.close()\n",
    "    return line_database\n",
    "\n",
    "def get_muscle_list(line_name):\n",
    "    \"\"\"function to get list of muscles for a given line \n",
    "    should make this general and move to src/ \"\"\"\n",
    "    line_database = get_line_database(line_name)\n",
    "    ln = line_name.split('_GFP')[0].split('GMR')[1]\n",
    "    muscle_names = list()\n",
    "    for key in line_database[ln].keys():\n",
    "        if line_database[ln][key] > 0:\n",
    "            muscle_names.append(key)\n",
    "    muscle_names = sorted(muscle_names)\n",
    "    #muscle_names = sorted(get_muscle_list(line_name))\n",
    "    return muscle_names\n",
    "\n",
    "def map_cross_cors(fly_num,sigs,muscle_list):\n",
    "    \"\"\"parallel function to calculate cross correlations\"\"\" \n",
    "    def calc_cross_cors(sigs,muscle_list):\n",
    "        import flylib\n",
    "        import numpy as np\n",
    "        #reload(flylib)\n",
    "        amp_corr_dict = dict()\n",
    "        freq_corr_dict = dict()\n",
    "        auto_corr_dict = dict()\n",
    "        import flylib\n",
    "        rwing = flylib.butter_bandpass_filter(sigs['Ph1'],0.02,20.0,0.022,order = 1)\n",
    "        wbf = sigs['wb_frequency']\n",
    "        wbf_filt = flylib.butter_bandpass_filter(wbf,0.02,20.0,0.022,order = 1)\n",
    "        StimCond = sigs['StimCond']\n",
    "        imlen = np.shape(sigs[muscle_list[0]])[0]\n",
    "        mask = ((StimCond<0) & (wbf >150))[:imlen]\n",
    "        times = sigs['times']\n",
    "        dt = (times[1]-times[0])\n",
    "        xcor_times = np.arange(0,np.sum(mask))*dt - dt*np.sum(mask)/2\n",
    "        from scipy import signal\n",
    "        for mname in muscle_list:\n",
    "            if not('ps' in mname):\n",
    "                msig = flylib.butter_bandpass_filter(sigs[mname],0.02,20.0,0.022,order = 1)\n",
    "                amp_corr_dict[mname] = signal.correlate(msig[mask],rwing[mask],mode = 'same')\n",
    "                freq_corr_dict[mname] = signal.correlate(msig[mask],wbf_filt[mask],mode = 'same')\n",
    "                auto_corr_dict[mname] = signal.correlate(msig[mask],msig[mask],mode = 'same')\n",
    "        return {'amp':amp_corr_dict,'freq':freq_corr_dict,'auto':auto_corr_dict,'times':xcor_times}\n",
    "    return {fly_num:calc_cross_cors(sigs,muscle_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create a tuple of arguments to pass to the map function\n",
    "map_data = dict()\n",
    "for swarmkey in swarm_data.keys():\n",
    "    muscle_list = get_muscle_list(swarmkey)\n",
    "    map_data[swarmkey] = ([key for key in swarm_data[swarmkey].keys()],\n",
    "                           [swarm_data[swarmkey][key]['sigs'] for key in swarm_data[swarmkey].keys()],\n",
    "                           [muscle_list for key in swarm_data[swarmkey].keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "#get the ipython clients\n",
    "from IPython.parallel import Client\n",
    "clients = Client() \n",
    "clients.block = True\n",
    "print clients.ids\n",
    "v = clients[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMR22H05_GFP\n",
      "GMR31E10\n",
      "GMR75B06_GFP\n",
      "GMR22H05\n",
      "GMR29E05_GFP\n",
      "GMR39E01\n",
      "GMR31E10_GFP\n",
      "GMR10A12\n",
      "GMR74F03_GFP\n",
      "GMR75B06\n",
      "GMR74F03\n",
      "GMR29E05\n",
      "GMR10A12_GFP\n"
     ]
    }
   ],
   "source": [
    "#map in chunks by swarm\n",
    "output_dict = dict()\n",
    "for swarmkey in swarm_data.keys():\n",
    "    print swarmkey\n",
    "    output_dict[swarmkey] = v.map(map_cross_cors,*map_data[swarmkey])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load the computed data back into the swarm_data dictionary\n",
    "for swarmkey in swarm_data.keys():\n",
    "    for i,fnum in enumerate([x.keys()[0] for x in output_dict[swarmkey]]):\n",
    "        swarm_data[swarmkey][fnum]['corr_data'] =  output_dict[swarmkey][i].values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/FlyDataC/FlyDB/Fly0458/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0459/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0460/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0438/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0439/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0440/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0441/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0444/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0445/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0446/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0447/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0453/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0455/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0456/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0461/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0462/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0463/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0450/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0452/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0432/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0433/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0430/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0431/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0434/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0435/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0436/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0437/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0442/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n",
      "/media/FlyDataC/FlyDB/Fly0443/\n",
      "['corr_data', 'fly_num', 'sigs', 'fly_path']\n"
     ]
    }
   ],
   "source": [
    "#save the dictionary as a pickle (need to write that dict to hdf5 wrapper)\n",
    "import cPickle\n",
    "f = open('extracted_sigs.cpkl','wb')\n",
    "for swarmkey in swarm_data.keys():\n",
    "    for fly in swarm_data[swarmkey].values():\n",
    "        print fly['fly_path']\n",
    "        print fly.keys()\n",
    "        data_path =  fly['fly_path'] + 'nnls_fits_no_bk_dF_F_corr_data.cpkl'\n",
    "        f = open(data_path,'wb')\n",
    "        cPickle.dump(fly['corr_data'],f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#notify me that the batch is done\n",
    "import smtplib\n",
    "server = smtplib.SMTP( \"smtp.gmail.com\", 587 )\n",
    "server.starttls()\n",
    "server.login( 'thlindsay1@gmail.com', 'cyp4501a1' )\n",
    "server.sendmail( 'test', '5412229957@txt.att.net', 'batch processing done' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ls -al /media/FlyDataC/FlyDB/Fly*/nnls_fits_no_bk_dF_F_corr_data.cpkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no input file\n"
     ]
    }
   ],
   "source": [
    "#### construct an interpolated matrix of cross correlation data\n",
    "xcor = list()\n",
    "flynums = list()\n",
    "sig_types = list()\n",
    "muscle_names = list()\n",
    "swarm_names = list()\n",
    "\n",
    "for swarm_name,swarm in gd.swarms.items():\n",
    "    for fly in swarm.flies:\n",
    "        try:\n",
    "            pkldata = fly.get_pkl_data('nnls_fits_no_bk_dF_F_corr_data.cpkl')\n",
    "            x = pkldata['times']\n",
    "            for sig_type_key in ['amp', 'freq', 'auto']:\n",
    "                for mkey in pkldata[sig_type_key].keys():\n",
    "                    y = pkldata[sig_type_key][mkey]\n",
    "                    from scipy import interpolate\n",
    "                    tck = interpolate.splrep(x, y, s=0)\n",
    "                    xnew = np.arange(-100,100,0.01)\n",
    "                    ynew = interpolate.splev(xnew, tck, der=0)\n",
    "                    xcor.append(ynew)\n",
    "                    muscle_names.append(mkey)\n",
    "                    sig_types.append(sig_type_key)\n",
    "                    swarm_names.append(swarm_name)\n",
    "                    flynums.append(fly.fly_num)\n",
    "        except IOError:\n",
    "            print 'no input file'\n",
    "\n",
    "xcor = np.array(xcor)\n",
    "flynums = np.array(flynums)\n",
    "sig_types = np.array(sig_types)\n",
    "muscle_names = np.array(muscle_names)\n",
    "swarm_names = np.array(swarm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('extracted_signal_correlations.hdf5')\n",
    "import h5py\n",
    "sig_cor = h5py.File('extracted_signal_correlations.hdf5')\n",
    "sig_cor['xcor'] = xcor\n",
    "sig_cor['fly_nums'] = flynums\n",
    "sig_cor['sig_types'] = sig_types\n",
    "sig_cor['muscle_names'] = muscle_names\n",
    "sig_cor['swarm_names'] = swarm_names\n",
    "sig_cor.flush()\n",
    "sig_cor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
