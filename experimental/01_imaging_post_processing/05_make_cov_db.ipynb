{"nbformat_minor": 0, "cells": [{"execution_count": 1, "cell_type": "code", "source": "import group_data as gd\nimport flylib\nimport numpy as np", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": 2, "cell_type": "code", "source": "%pylab inline\n%config InlineBackend.figure_format = 'svg'\nimport pylab as plb\nplb.rcParams['pdf.fonttype'] = 42", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Populating the interactive namespace from numpy and matplotlib\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"source": "### Calculate the cross covariance data for each signal type and add it to the trial_db", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "#fit to each fly in serial (block) but break up the data to run in parallel within a fly.\nfrom IPython.parallel import Client\nclients = Client() \nclients.block = True\nprint clients.ids\nv = clients[:]", "outputs": [{"ename": "IOError", "evalue": "Connection file u'~/.ipython/profile_nbserver/security/ipcontroller-client.json' not found.\nYou have attempted to connect to an IPython Cluster but no Controller could be found.\nPlease double-check your configuration and ensure that a cluster is running.", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)", "\u001b[1;32m<ipython-input-3-c06cf5f5e720>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fit to each fly in serial (block) but break up the data to run in parallel within a fly.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblock\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32m/home/psilentp/anaconda/lib/python2.7/site-packages/IPython/parallel/client/client.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url_file, profile, profile_dir, ipython_dir, context, debug, sshserver, sshkey, password, paramiko, timeout, cluster_id, **extra_args)\u001b[0m\n\u001b[0;32m    405\u001b[0m                         \u001b[0mno_file_msg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                     ])\n\u001b[1;32m--> 407\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0murl_file\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_file_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mIOError\u001b[0m: Connection file u'~/.ipython/profile_nbserver/security/ipcontroller-client.json' not found.\nYou have attempted to connect to an IPython Cluster but no Controller could be found.\nPlease double-check your configuration and ensure that a cluster is running."], "output_type": "error"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": null, "cell_type": "code", "source": "#amplitude\nimport h5py\nimport numpy as np\ntrial_db = h5py.File('trial_db.hdf5','a')\n\nmuscle_list =  ['b1','b2','b3',\n                'i1','i2',\n                'iii1','iii3','iii24',\n                'hg1','hg2','hg3','hg4',\n                'tpd','tpv','ttm','pr']\nfrom scipy.signal import correlate\nfrom scipy.signal import detrend\ncorr_dict = dict()\n\nfor mname in muscle_list:\n    sarray1 = np.array(trial_db[mname])\n    sarray2 = np.array(trial_db['Ph1'])\n    xdata = [detrend(a1[np.isfinite(a1)]) for a1 in sarray1]\n    ydata = [detrend(a1[np.isfinite(a1)]) for a1 in sarray2]\n    corrlist = v.map(correlate,xdata,ydata,['same']*len(xdata))\n    corrmtrx = np.empty((len(corrlist),1149))\n    corrmtrx[:] = np.nan\n    for i,cd in enumerate(corrlist):\n        if np.shape(cd)[0] > 1147:\n            corrmtrx[i,:1147] = cd[:1147]\n        else:\n            pass\n    corr_dict[mname] = corrmtrx\nfor key in corr_dict:\n    trial_db.create_dataset('xcov_amp' + key,data = np.array(corr_dict[key]),  compression=\"gzip\",compression_opts=5)\ntrial_db.flush()", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": null, "cell_type": "code", "source": "#frequency\nimport h5py\nimport numpy as np\ntrial_db = h5py.File('trial_db.hdf5','a')\n\nmuscle_list =  ['b1','b2','b3',\n                'i1','i2',\n                'iii1','iii3','iii24',\n                'hg1','hg2','hg3','hg4',\n                'tpd','tpv','ttm','pr']\nfrom scipy.signal import correlate\nfrom scipy.signal import detrend\ncorr_dict = dict()\n\ndef wrapped_correlate(xdata,ydata,mode):\n    from scipy.signal import correlate\n    import numpy as np\n    if np.squeeze(np.shape(xdata)) == np.squeeze(np.shape(ydata)):\n        return correlate(xdata,ydata,mode)\n    else:\n        return np.nan\n     \nfor mname in muscle_list:\n    sarray1 = np.array(trial_db[mname])\n    sarray2 = np.array(trial_db['wb_frequency'])\n    xdata = [detrend(a1[np.isfinite(a1)]) for a1 in sarray1]\n    ydata = [detrend(a1[np.isfinite(a1)]) for a1 in sarray2]\n    corrlist = v.map(wrapped_correlate,xdata,ydata,['same']*len(xdata))\n    corrmtrx = np.empty((len(corrlist),1149))\n    corrmtrx[:] = np.nan\n    for i,cd in enumerate(corrlist):\n        if np.squeeze(np.shape(cd)) > 1147:\n            corrmtrx[i,:1147] = cd[:1147]\n        else:\n            pass\n    corr_dict[mname] = corrmtrx\nfor key in corr_dict:\n    trial_db.create_dataset('xcov_freq' + key,data = np.array(corr_dict[key]),  compression=\"gzip\",compression_opts=5)\ntrial_db.flush()", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"source": "### summarize xcov data accross flies - just stripe fixation for now.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 3, "cell_type": "code", "source": "import h5py\ntrial_db = h5py.File('trial_db.hdf5','r')\nxi = np.linspace(0,23,1150)\ntlag = xi-xi[1150/2.0]\ntlag = tlag[:1149]\nmuscle_list =  ['b1','b2','b3',\n                'i1','i2',\n                'iii1','iii3','iii24',\n                'hg1','hg2','hg3','hg4',\n                'tpd','tpv','ttm','pr']\nswarm_names = np.array(trial_db['swarm_names'])\nfly_numbers = np.array(trial_db['fly_numbers'])\nwb_frequency = np.array(trial_db['wb_frequency'])\ntrial_names = np.array(trial_db['trial_names'])\nwb_selection = np.sum(wb_frequency >50,axis = 1)>1000\nswarm_set = [sw for sw in set(swarm_names) if not('pr' in sw)]\nfly_set = set(fly_numbers)", "outputs": [{"output_type": "stream", "name": "stderr", "text": "/home/psilentp/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:15: RuntimeWarning: invalid value encountered in greater\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 4, "cell_type": "code", "source": "#calculate the median xcov functions between stroke amplitude and muscle activity\n#load into a dictionary keyed by group and then muscle\ncov_dict = dict()\ntrial_selection = (trial_names == 'stripe_fix')\nwb_selection = np.sum(wb_frequency >50)>1000\nwb_selection &= trial_selection\nfor swarm in swarm_set:\n    print swarm\n    swarm_selection = (swarm == swarm_names) & wb_selection\n    cov_dict[swarm] = dict()\n    for mname in muscle_list:\n        cov_dict[swarm][mname] = list()\n        for flynum in fly_set:\n            selection  = (flynum == fly_numbers) & swarm_selection\n            if sum(selection) > 2:\n                trace = nanmedian(np.array(trial_db['xcov_amp%s'%(mname)])[selection,:],axis = 0)\n                #trace = np.nanmean(np.array(trial_db['xcov_amp%s'%(mname)])[selection,:],axis = 0)\n                #trace = nanmedian(np.array(trial_db['xcov_amp_ms%s'%(mname)])[selection,:],axis = 0)\n                cov_dict[swarm][mname].append(trace)                \n#xcov_amp_ms", "outputs": [{"output_type": "stream", "name": "stderr", "text": "/home/psilentp/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: RuntimeWarning: invalid value encountered in greater\n/home/psilentp/anaconda/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:662: RuntimeWarning: All-NaN slice encountered\n  warnings.warn(\"All-NaN slice encountered\", RuntimeWarning)\n"}, {"output_type": "stream", "name": "stdout", "text": "GMR22H05_GFP\nGMR31E10\nGMR75B06_GFP\nGMR22H05\nGMR29E05_GFP\nGMR39E01\nGMR31E10_GFP\nGMR10A12\nGMR74F03_GFP\nGMR39E01_GFP\nGMR75B06\nGMR74F03\nGMR29E05\nGMR10A12_GFP\n"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 5, "cell_type": "code", "source": "import h5py\nimport os\n#os.listdir('./')\nos.remove('cov_db_amp_sf.hdf5')\ncov_db = h5py.File('cov_db_amp_sf.hdf5','a')\nfor key in swarm_set:\n    cov_db.create_group(key)\n    for key2 in cov_dict[key].keys():\n        cov_db[key].create_dataset(key2,data = np.array(cov_dict[key][key2]),  compression=\"gzip\",compression_opts=5)\ncov_db.flush()", "outputs": [], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 1, "cell_type": "code", "source": "#calculate the median xcov functions between stroke frequency and muscle activity\n#load into a dictionary keyed by group and then muscle\ncov_dict_freq = dict()\ntrial_selection = (trial_names == 'stripe_fix')\nwb_selection = np.sum(wb_frequency >50)>1000\nwb_selection &= trial_selection\nfor swarm in swarm_set:\n    print swarm\n    swarm_selection = (swarm == swarm_names) & wb_selection\n    cov_dict_freq[swarm] = dict()\n    for mname in muscle_list:\n        cov_dict_freq[swarm][mname] = list()\n        for flynum in fly_set:\n            selection  = (flynum == fly_numbers) & swarm_selection\n            if sum(selection) > 2:\n                trace = nanmedian(np.array(trial_db['xcov_freq%s'%(mname)])[selection,:],axis = 0)\n                cov_dict_freq[swarm][mname].append(trace)", "outputs": [{"ename": "NameError", "evalue": "name 'trial_names' is not defined", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32m<ipython-input-1-982da8b26b4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#load into a dictionary keyed by group and then muscle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcov_dict_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrial_selection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrial_names\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'stripe_fix'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mwb_selection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwb_frequency\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mwb_selection\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[0mtrial_selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mNameError\u001b[0m: name 'trial_names' is not defined"], "output_type": "error"}], "metadata": {"collapsed": false, "trusted": false}}, {"execution_count": 6, "cell_type": "code", "source": "import h5py\nimport os\n#os.listdir('./')\n#os.remove('cov_db_freq_sf.hdf5')\ncov_db_freq = h5py.File('cov_db_freq_sf.hdf5','a')\nfor key in swarm_set:\n    cov_db_freq.create_group(key)\n    for key2 in cov_dict_freq[key].keys():\n        cov_db_freq[key].create_dataset(key2,data = np.array(cov_dict_freq[key][key2]),  compression=\"gzip\",compression_opts=5)\ncov_db_freq.flush()", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}, {"execution_count": null, "cell_type": "code", "source": "", "outputs": [], "metadata": {"collapsed": true, "trusted": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.9", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}